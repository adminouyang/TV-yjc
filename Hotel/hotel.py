import eventlet
eventlet.monkey_patch()
import time
import datetime
from threading import Thread, Lock
import os
import re
from queue import Queue, Empty
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import concurrent.futures
import json
from bs4 import BeautifulSoup

# é…ç½®åŒº
FOFA_URLS = {
    "https://fofa.info/result?qbase64=ImlwdHYvbGl2ZS96aF9jbi5qcyIgJiYgY291bnRyeT0iQ04i": "ip.txt",
}
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

IP_DIR = "Hotel/ip"
# åˆ›å»ºIPç›®å½•
if not os.path.exists(IP_DIR):
    os.makedirs(IP_DIR)
    
# IP è¿è¥å•†åˆ¤æ–­
def get_isp(ip):
    # æ›´å‡†ç¡®çš„IPæ®µåŒ¹é…
    telecom_pattern = r"^(1\.|14\.|27\.|36\.|39\.|42\.|49\.|58\.|60\.|101\.|106\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.|175\.|182\.|183\.|202\.|203\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
    unicom_pattern = r"^(42\.1[0-9]{0,2}|43\.|58\.|59\.|60\.|61\.|110\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|171\.8[0-9]|171\.9[0-9]|171\.1[0-9]{2}|175\.|182\.|183\.|210\.|211\.|218\.|219\.|220\.|221\.|222\.)"
    mobile_pattern = r"^(36\.|37\.|38\.|39\.1[0-9]{0,2}|42\.2|42\.3|47\.|106\.|111\.|112\.|113\.|114\.|115\.|116\.|117\.|118\.|119\.|120\.|121\.|122\.|123\.|124\.|125\.|126\.|134\.|135\.|136\.|137\.|138\.|139\.|150\.|151\.|152\.|157\.|158\.|159\.|170\.|178\.|182\.|183\.|184\.|187\.|188\.|189\.)"
    
    if re.match(telecom_pattern, ip):
        return "ç”µä¿¡"
    elif re.match(unicom_pattern, ip):
        return "è”é€š"
    elif re.match(mobile_pattern, ip):
        return "ç§»åŠ¨"
    else:
        return "æœªçŸ¥"

# è·å–IPåœ°ç†ä¿¡æ¯
def get_ip_info(ip_port):
    try:
        ip = ip_port.split(":")[0]
        # æ·»åŠ é‡è¯•æœºåˆ¶
        for attempt in range(3):
            try:
                res = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", 
                                  timeout=10, headers=HEADERS)
                if res.status_code == 200:
                    data = res.json()
                    if data.get("status") == "success":
                        province = data.get("regionName", "æœªçŸ¥")
                        isp = get_isp(ip)
                        return province, isp, ip_port
                break
            except requests.RequestException:
                if attempt == 2:  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    return None, None, ip_port
                time.sleep(1)
    except Exception:
        pass
    return None, None, ip_port

# è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹å¹¶å»é‡
def read_existing_ips(filepath):
    existing_ips = set()
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    ip = line.strip()
                    if ip:  # ç¡®ä¿ä¸æ˜¯ç©ºè¡Œ
                        existing_ips.add(ip)
            print(f"ğŸ“– ä» {os.path.basename(filepath)} è¯»å–åˆ° {len(existing_ips)} ä¸ªç°æœ‰IP")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
    return existing_ips
    
# ç¬¬ä¸€é˜¶æ®µï¼šçˆ¬å–å’Œåˆ†ç±»
def first_stage():
    all_ips = set()
    
    for url, filename in FOFA_URLS.items():
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å– {filename} ...")
        try:
            r = requests.get(url, headers=HEADERS, timeout=15)
            # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
            urls_all = re.findall(r'<a href="http://(.*?)"', r.text)
            # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„IP:ç«¯å£æ ¼å¼
            all_ips.update(u.strip() for u in urls_all)
            
            print(f"âœ… ä» {filename} è·å–åˆ° {len(urls_all)} ä¸ªIPï¼Œå…¶ä¸­ {len(all_ips)} ä¸ªæœ‰æ•ˆ")
        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥ï¼š{e}")
        time.sleep(3)
    
    print(f"ğŸ” æ€»å…±è·å–åˆ° {len(all_ips)} ä¸ªæœ‰æ•ˆIP")
    
    # ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€ŸIPä¿¡æ¯æŸ¥è¯¢
    province_isp_dict = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_ip = {executor.submit(get_ip_info, ip): ip for ip in all_ips}
        
        for future in concurrent.futures.as_completed(future_to_ip):
            province, isp, ip_port = future.result()
            if province and isp and isp != "æœªçŸ¥":
                fname = f"{province}{isp}.txt"
                province_isp_dict.setdefault(fname, set()).add(ip_port)
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼Œä¸å»é‡ï¼‰
    for fname, new_ips in province_isp_dict.items():
        filepath = os.path.join(IP_DIR, fname)
        
        # è¯»å–ç°æœ‰IP
        existing_ips = read_existing_ips(filepath)
        
        # åˆå¹¶æ–°æ—§IPå¹¶å»é‡
        all_ips_for_file = existing_ips.union(new_ips)
        
        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            for ip in all_ips_for_file:
                f.write(ip + '\n')
        
        added_count = len(all_ips_for_file) - len(existing_ips)
        print(f"ğŸ’¾ å·²æ›´æ–° {fname}ï¼Œæ–°å¢ {added_count} ä¸ªIPï¼Œæ€»è®¡ {len(all_ips_for_file)} ä¸ªIP")
    
    print(f"âœ… ä»»åŠ¡å®Œæˆï¼å…±å¤„ç† {len(province_isp_dict)} ä¸ªåˆ†ç±»æ–‡ä»¶")

# æŒ‰ç…§çœä»½åˆ†ç±»ä¿å­˜IP
def save_ips_by_province(ips):
    province_map = {}
    for ip_port in ips:
        ip = ip_port.split(':')[0]
        first_octet = ip.split('.')[0]
        if first_octet in ['1', '2']:
            province = 'åŒ—äº¬'
        elif first_octet in ['3', '4']:
            province = 'ä¸Šæµ·'
        elif first_octet in ['5', '6']:
            province = 'å¹¿ä¸œ'
        elif first_octet in ['7', '8']:
            province = 'æµ™æ±Ÿ'
        else:
            province = 'å…¶ä»–'
        
        if province not in province_map:
            province_map[province] = []
        province_map[province].append(ip_port)
    
    for province, ip_list in province_map.items():
        filename = os.path.join(IP_DIR, f"{province}.txt")
        with open(filename, 'w', encoding='utf-8') as f:
            for ip_port in ip_list:
                f.write(f"{ip_port}\n")
        print(f"ä¿å­˜ {len(ip_list)} ä¸ªIPåˆ° {filename}")

# ä»URLè·å–IPä¿¡æ¯
def fetch_ips_from_urls():
    all_ips = []
    for url, filename in FOFA_URLS.items():
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            if 'application/json' in response.headers.get('content-type', ''):
                data = response.json()
                for item in data.get('data', []):
                    ip = item.get('ip')
                    port = item.get('port')
                    if ip and port:
                        all_ips.append(f"{ip}:{port}")
            else:
                soup = BeautifulSoup(response.text, 'html.parser')
                tables = soup.find_all('table')
                for table in tables:
                    rows = table.find_all('tr')
                    for row in rows:
                        cells = row.find_all('td')
                        if len(cells) >= 2:
                            ip_text = cells[0].get_text().strip()
                            port_text = cells[1].get_text().strip()
                            if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', ip_text) and port_text.isdigit():
                                all_ips.append(f"{ip_text}:{port_text}")
        except Exception as e:
            print(f"ä»URL {url} è·å–IPé”™è¯¯: {e}")
    return all_ips

# é¢‘é“åˆ†ç±»å®šä¹‰
CHANNEL_CATEGORIES = {
    "å¤®è§†é¢‘é“": [
        "CCTV1", "CCTV2", "CCTV3", "CCTV4", "CCTV4æ¬§æ´²", "CCTV4ç¾æ´²", "CCTV5", "CCTV5+", "CCTV6", "CCTV7",
        "CCTV8", "CCTV9", "CCTV10", "CCTV11", "CCTV12", "CCTV13", "CCTV14", "CCTV15", "CCTV16", "CCTV17",
        "å…µå™¨ç§‘æŠ€", "é£äº‘éŸ³ä¹", "é£äº‘è¶³çƒ", "é£äº‘å‰§åœº", "æ€€æ—§å‰§åœº", "ç¬¬ä¸€å‰§åœº", "å¥³æ€§æ—¶å°š", "ä¸–ç•Œåœ°ç†", "å¤®è§†å°çƒ", "é«˜å°”å¤«ç½‘çƒ",
        "å¤®è§†æ–‡åŒ–ç²¾å“", "å«ç”Ÿå¥åº·", "ç”µè§†æŒ‡å—", "è€æ•…äº‹", "ä¸­å­¦ç”Ÿ", "å‘ç°ä¹‹æ—…", "ä¹¦æ³•é¢‘é“", "å›½å­¦é¢‘é“", "ç¯çƒå¥‡è§‚"
    ],
    "å«è§†é¢‘é“": [
        "æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†", "æ±Ÿè‹å«è§†", "ä¸œæ–¹å«è§†", "æ·±åœ³å«è§†", "åŒ—äº¬å«è§†", "å¹¿ä¸œå«è§†", "å¹¿è¥¿å«è§†", "ä¸œå—å«è§†", "æµ·å—å«è§†",
        "æ²³åŒ—å«è§†", "æ²³å—å«è§†", "æ¹–åŒ—å«è§†", "æ±Ÿè¥¿å«è§†", "å››å·å«è§†", "é‡åº†å«è§†", "è´µå·å«è§†", "äº‘å—å«è§†", "å¤©æ´¥å«è§†", "å®‰å¾½å«è§†",
        "å±±ä¸œå«è§†", "è¾½å®å«è§†", "é»‘é¾™æ±Ÿå«è§†", "å‰æ—å«è§†", "å†…è’™å¤å«è§†", "å®å¤å«è§†", "å±±è¥¿å«è§†", "é™•è¥¿å«è§†", "ç”˜è‚ƒå«è§†", "é’æµ·å«è§†",
        "æ–°ç–†å«è§†", "è¥¿è—å«è§†", "ä¸‰æ²™å«è§†", "å…µå›¢å«è§†", "å»¶è¾¹å«è§†", "å®‰å¤šå«è§†", "åº·å·´å«è§†", "å†œæ—å«è§†", "å±±ä¸œæ•™è‚²å«è§†",
        "ä¸­å›½æ•™è‚²1å°", "ä¸­å›½æ•™è‚²2å°", "ä¸­å›½æ•™è‚²3å°", "ä¸­å›½æ•™è‚²4å°", "æ—©æœŸæ•™è‚²"
    ],
    "æ•°å­—é¢‘é“": [
        "CHCåŠ¨ä½œç”µå½±", "CHCå®¶åº­å½±é™¢", "CHCå½±è¿·ç”µå½±", "æ·˜ç”µå½±", "æ·˜ç²¾å½©", "æ·˜å‰§åœº", "æ·˜4K", "æ·˜å¨±ä¹", "æ·˜BABY", "æ·˜èŒå® ", "é‡æ¸©ç»å…¸",
         "IPTVæˆæ›²", "æ±‚ç´¢çºªå½•", "æ±‚ç´¢ç§‘å­¦",
        "æ±‚ç´¢ç”Ÿæ´»", "æ±‚ç´¢åŠ¨ç‰©", "çºªå®äººæ–‡", "é‡‘é¹°çºªå®", "çºªå®ç§‘æ•™", "ç›å½©é’å°‘", "ç›å½©ç«æŠ€", "ç›å½©ç¯®çƒ", "ç›å½©å¹¿åœºèˆ", "é­…åŠ›è¶³çƒ", "äº”æ˜Ÿä½“è‚²", "ä½“è‚²èµ›äº‹",
        "åŠ²çˆ†ä½“è‚²", "å¿«ä¹å‚é’“", "èŒ¶é¢‘é“", "å…ˆé”‹ä¹’ç¾½", "å¤©å…ƒå›´æ£‹", "æ±½æ‘©", "è½¦è¿·é¢‘é“", "æ¢¨å›­é¢‘é“", "æ–‡ç‰©å®åº“", "æ­¦æœ¯ä¸–ç•Œ",
        "ä¹æ¸¸", "ç”Ÿæ´»æ—¶å°š", "éƒ½å¸‚å‰§åœº", "æ¬¢ç¬‘å‰§åœº", "æ¸¸æˆé£äº‘", "é‡‘è‰²å­¦å ‚", "åŠ¨æ¼«ç§€åœº", "æ–°åŠ¨æ¼«", "å¡é…·å°‘å„¿", "é‡‘é¹°å¡é€š", "ä¼˜æ¼«å¡é€š", "å“ˆå“ˆç‚«åŠ¨", "å˜‰ä½³å¡é€š", 
        "ä¼˜ä¼˜å®è´", "ä¸­å›½äº¤é€š", "ä¸­å›½å¤©æ°”", "æµ·çœ‹å¤§ç‰‡", "ç»å…¸ç”µå½±", "ç²¾å½©å½±è§†", "å–œå‰§å½±é™¢", "åŠ¨ä½œå½±é™¢", "ç²¾å“å‰§åœº", "ç½‘ç»œæ£‹ç‰Œ", 
    ],
    "æ¸¯æ¾³å°é¢‘é“": [
        "å‡¤å‡°å«è§†ä¸­æ–‡å°", "å‡¤å‡°å«è§†èµ„è®¯å°", "å‡¤å‡°å«è§†é¦™æ¸¯å°", "å‡¤å‡°å«è§†ç”µå½±å°", "é¾™ç¥¥æ—¶ä»£","æ˜Ÿç©ºå«è§†", "CHANNEL[V]",  "","", "", "", "", "", "", "",
    ],
    "å®‰å¾½é¢‘é“": [
        "å®‰å¾½å½±è§†", "å®‰å¾½ç»æµç”Ÿæ´»", "å®‰å¾½å…¬å…±", "å®‰å¾½ç»¼è‰ºä½“è‚²", "å®‰å¾½å†œä¸šç§‘æ•™", "é˜œé˜³å…¬å…±é¢‘é“", "é©¬éå±±æ–°é—»ç»¼åˆ", "é©¬éå±±å…¬å…±", "", "", "", "ç¯çƒå¥‡è§‚",
        "ä¸´æ³‰ä¸€å°", "", "", "", "", "", "", "",
        "", "", "", "", "", "", "", "", "", "", "",
    ],
    "ä¸Šæµ·é¢‘é“": [
        "æ–°é—»ç»¼åˆ", "éƒ½å¸‚é¢‘é“", "ä¸œæ–¹å½±è§†", "çºªå®äººæ–‡", "ç¬¬ä¸€è´¢ç»", "äº”æ˜Ÿä½“è‚²", "ä¸œæ–¹è´¢ç»", "ICSé¢‘é“", "ä¸Šæµ·æ•™è‚²å°", "ä¸ƒå½©æˆå‰§", "æ³•æ²»å¤©åœ°", "é‡‘è‰²å­¦å ‚",
        "åŠ¨æ¼«ç§€åœº", "æ¬¢ç¬‘å‰§åœº4K", "ç”Ÿæ´»æ—¶å°š", "", "", "", "", "",
        "", "", "", "", "", "", "", "", "", "", "",
    ],
    "æ¹–å—é¢‘é“": [
        "æ¹–å—å›½é™…", "æ¹–å—ç”µå½±", "æ¹–å—ç”µè§†å‰§", "æ¹–å—ç»è§†", "æ¹–å—å¨±ä¹", "æ¹–å—å…¬å…±", "æ¹–å—éƒ½å¸‚","æ¹–å—æ•™è‚²", "èŠ’æœäº’å¨±", "é•¿æ²™æ–°é—»", "é•¿æ²™æ”¿æ³•", "é•¿æ²™å½±è§†", "é•¿æ²™å¥³æ€§", "",
        "ç›Šé˜³å…¬å…±", "æŠ—æˆ˜å‰§åœº", "å¤è£…å‰§åœº", "é«˜æ¸…é™¢çº¿", "å…ˆé”‹å…µç¾½", "", "", "",
        "", "", "", "", "", "", "", "", "", "", "",
    ],
    "æ¹–åŒ—é¢‘é“": [
        "æ¹–åŒ—ç»¼åˆ", "æ¹–åŒ—å½±è§†", "æ¹–åŒ—ç”Ÿæ´»", "æ¹–åŒ—æ•™è‚²", "æ¹–åŒ—ç»è§†", "è†å·æ–°é—»", "è†å·å„ä¸Š", "", "","", "", "", "", "", "", "",
    ],
    "å±±ä¸œé¢‘é“": [
         "å±±ä¸œç»¼è‰º", "çƒŸå°æ–°é—»","", "", "", "", "", "", "",
    ],
    "å¹¿ä¸œé¢‘é“": [
        "", "", "", "", "", "", "å¹¿ä¸œç§‘æ•™", "å¹¿ä¸œä½“è‚²", "å¹¿å·", "å¹¿ä¸œç æ±Ÿ","å˜‰ä½³å¡é€š", "èŒ‚åç»¼åˆ", "", "", "", "", "",
    ],
    "å¹¿è¥¿é¢‘é“": [
        "å¹¿è¥¿å½±è§†", "å¹¿è¥¿ç»¼è‰º", "å¹¿è¥¿éƒ½å¸‚", "å¹¿è¥¿æ–°é—»", "å¹¿è¥¿ç§»åŠ¨", "å¹¿è¥¿ç§‘æŠ€", "ç²¾å½©å½±è§†", "å¹³å—å°", "å—å®å½±è§†", "ç‰æ—æ–°é—»ç»¼åˆ","", "", "", "", "", "", "",
    ],
    "å››å·é¢‘é“": [
        "", "", "", "", "", "", "", "", "è“¬å®‰ç”µè§†å°", "","", "", "", "", "", "", "",
    ],
    "æ–°ç–†é¢‘é“": [
        "æ–°ç–†2", "æ–°ç–†3", "æ–°ç–†4", "æ–°ç–†5", "æ–°ç–†6", "æ–°ç–†7", "æ–°ç–†8", "æ–°ç–†9", "", "","", "", "", "", "", "", "",
    ],
}

# æ”¹è¿›çš„é¢‘é“åç§°æ˜ å°„ï¼Œä½¿ç”¨ç²¾ç¡®åŒ¹é…
CHANNEL_MAPPING = {
    "CCTV1": [r"CCTV[-_]?1(?!\d)", r"CCTV1(?!\d)", r"^CCTV-1$", r"^CCTV1$"],
    "CCTV2": [r"CCTV[-_]?2(?!\d)", r"CCTV2(?!\d)", r"^CCTV-2$", r"^CCTV2$"],
    "CCTV3": [r"CCTV[-_]?3(?!\d)", r"CCTV3(?!\d)", r"^CCTV-3$", r"^CCTV3$"],
    "CCTV4": [r"CCTV[-_]?4(?!\d)", r"CCTV4(?!\d)", r"^CCTV-4$", r"^CCTV4$"],
    "CCTV5": [r"CCTV[-_]?5(?!\d)", r"CCTV5(?!\d)", r"^CCTV-5$", r"^CCTV5$"],
    "CCTV5+": [r"CCTV[-_]?5\+", r"CCTV5\+", r"CCTV-5\+", r"CCTV5plus", r"CCTV-5plus"],
    "CCTV6": [r"CCTV[-_]?6(?!\d)", r"CCTV6(?!\d)", r"^CCTV-6$", r"^CCTV6$"],
    "CCTV7": [r"CCTV[-_]?7(?!\d)", r"CCTV7(?!\d)", r"^CCTV-7$", r"^CCTV7$"],
    "CCTV8": [r"CCTV[-_]?8(?!\d)", r"CCTV8(?!\d)", r"^CCTV-8$", r"^CCTV8$"],
    "CCTV9": [r"CCTV[-_]?9(?!\d)", r"CCTV9(?!\d)", r"^CCTV-9$", r"^CCTV9$"],
    "CCTV10": [r"CCTV[-_]?10", r"CCTV10", r"^CCTV-10$"],
    "CCTV11": [r"CCTV[-_]?11", r"CCTV11", r"^CCTV-11$"],
    "CCTV12": [r"CCTV[-_]?12", r"CCTV12", r"^CCTV-12$"],
    "CCTV13": [r"CCTV[-_]?13", r"CCTV13", r"^CCTV-13$"],
    "CCTV14": [r"CCTV[-_]?14", r"CCTV14", r"^CCTV-14$"],
    "CCTV15": [r"CCTV[-_]?15", r"CCTV15", r"^CCTV-15$"],
    "CCTV16": [r"CCTV[-_]?16", r"CCTV16", r"^CCTV-16$"],
    "CCTV17": [r"CCTV[-_]?17", r"CCTV17", r"^CCTV-17$"],
    
    "CCTV4æ¬§æ´²": [r"CCTV[-_]?4æ¬§æ´²", r"CCTV4æ¬§æ´²", r"CCTV-4æ¬§æ´²"],
    "CCTV4ç¾æ´²": [r"CCTV[-_]?4ç¾æ´²", r"CCTV4ç¾æ´²", r"CCTV-4ç¾æ´²"],
    
    "å…µå™¨ç§‘æŠ€": [r"å…µå™¨ç§‘æŠ€", r"å…µå™¨"],
    "é£äº‘éŸ³ä¹": [r"é£äº‘éŸ³ä¹"],
    "ç¬¬ä¸€å‰§åœº": [r"ç¬¬ä¸€å‰§åœº"],
    "é£äº‘è¶³çƒ": [r"é£äº‘è¶³çƒ"],
    "é£äº‘å‰§åœº": [r"é£äº‘å‰§åœº"],
    "æ€€æ—§å‰§åœº": [r"æ€€æ—§å‰§åœº"],
    "å¥³æ€§æ—¶å°š": [r"å¥³æ€§æ—¶å°š"],
    "ä¸–ç•Œåœ°ç†": [r"ä¸–ç•Œåœ°ç†"],
    "å¤®è§†å°çƒ": [r"å¤®è§†å°çƒ"],
    "é«˜å°”å¤«ç½‘çƒ": [r"é«˜å°”å¤«ç½‘çƒ", r"é«˜å°”å¤«Â·ç½‘çƒ", r"å¤®è§†é«˜ç½‘"],
    "å¤®è§†æ–‡åŒ–ç²¾å“": [r"å¤®è§†æ–‡åŒ–ç²¾å“", r"æ–‡åŒ–ç²¾å“"],
    "å«ç”Ÿå¥åº·": [r"å«ç”Ÿå¥åº·"],
    "ç”µè§†æŒ‡å—": [r"ç”µè§†æŒ‡å—"],
    "ä¸œå—å«è§†": [r"ç¦å»ºä¸œå—"],
    "ä¸œæ–¹å«è§†": [r"ä¸Šæµ·å«è§†"],
    "å†œæ—å«è§†": [r"é™•è¥¿å†œæ—å«è§†"],
    "æ±Ÿè¥¿å«è§†": [r"æ±Ÿè¥¿å«è§†"],
    "é»‘é¾™æ±Ÿå«è§†": [r"é»‘é¾™æ±Ÿå«è§†"],
    "å‰æ—å«è§†": [r"å‰æ—å«è§†"],
    "ç”˜è‚ƒå«è§†": [r"ç”˜è‚ƒå«è§†"],
    "æ¹–å—å«è§†": [r"æ¹–å—å«è§†"],
    "æ²³å—å«è§†": [r"æ²³å—å«è§†"],
    "æ²³åŒ—å«è§†": [r"æ²³åŒ—å«è§†"],
    "æ¹–åŒ—å«è§†": [r"æ¹–åŒ—å«è§†"],
    "é‡åº†å«è§†": [r"é‡åº†å«è§†"],
    "å¹¿è¥¿å«è§†": [r"å¹¿è¥¿å«è§†"],
    "å¤©æ´¥å«è§†": [r"å¤©æ´¥å«è§†"],
    "å±±ä¸œå«è§†": [r"å±±ä¸œå«è§†"],
    "æ˜Ÿç©ºå«è§†": [r"æ˜Ÿç©ºå«è§†", r"XFæ˜Ÿç©ºå«è§†", r"æ˜Ÿç©ºè¡›è¦–"],
    "å››å·å«è§†": [r"å››å·å«è§†"],
    "è´µå·å«è§†": [r"è´µå·å«è§†"],
    "å—æ–¹å«è§†": [r"å—æ–¹å«è§†"],
    "å†…è’™å¤å«è§†": [r"å†…è’™å¤å«è§†", r"å†…è’™å¤", r"å†…è’™å«è§†"],
    "åº·å·´å«è§†": [r"åº·å·´å«è§†"],
    "å±±ä¸œæ•™è‚²å«è§†": [r"å±±ä¸œæ•™è‚²"],
    "æ–°ç–†å«è§†": [r"æ–°ç–†å«è§†", r"æ–°ç–†1"],
    "è¥¿è—å«è§†": [r"è¥¿è—å«è§†", r"XZTV2"],
    
    "ä¸­å›½æ•™è‚²1å°": [r"CETV[-_]?1", r"CETV1", r"ä¸­å›½æ•™è‚²[-_]?1", r"ä¸­å›½æ•™è‚²1", r"ä¸­å›½æ•™è‚²ä¸€å°"],
    "ä¸­å›½æ•™è‚²2å°": [r"CETV[-_]?2", r"CETV2", r"ä¸­å›½æ•™è‚²[-_]?2", r"ä¸­å›½æ•™è‚²2", r"ä¸­å›½æ•™è‚²äºŒå°"],
    "ä¸­å›½æ•™è‚²3å°": [r"CETV[-_]?3", r"CETV3", r"ä¸­å›½æ•™è‚²[-_]?3", r"ä¸­å›½æ•™è‚²3", r"ä¸­å›½æ•™è‚²ä¸‰å°"],
    "ä¸­å›½æ•™è‚²4å°": [r"CETV[-_]?4", r"CETV4", r"ä¸­å›½æ•™è‚²[-_]?4", r"ä¸­å›½æ•™è‚²4", r"ä¸­å›½æ•™è‚²å››å°"],
    
    "CHCåŠ¨ä½œç”µå½±": [r"CHCåŠ¨ä½œç”µå½±", r"åŠ¨ä½œç”µå½±"],
    "CHCå®¶åº­å½±é™¢": [r"CHCå®¶åº­å½±é™¢", r"å®¶åº­å½±é™¢"],
    "CHCå½±è¿·ç”µå½±": [r"CHCå½±è¿·ç”µå½±", r"å½±è¿·ç”µå½±", r"CHCé«˜æ¸…ç”µå½±", r"é«˜æ¸…ç”µå½±"],
    
    "æ·˜ç”µå½±": [r"æ·˜ç”µå½±", r"IPTVæ·˜ç”µå½±"],
    "æ·˜ç²¾å½©": [r"æ·˜ç²¾å½©", r"IPTVæ·˜ç²¾å½©"],
    "æ·˜å‰§åœº": [r"æ·˜å‰§åœº", r"IPTVæ·˜å‰§åœº"],
    "æ·˜4K": [r"æ·˜4K", r"IPTVæ·˜4K", r"æ·˜ 4K"],
    "æ·˜å¨±ä¹": [r"æ·˜å¨±ä¹", r"IPTVæ·˜å¨±ä¹"],
    "æ·˜BABY": [r"æ·˜BABY", r"IPTVæ·˜BABY", r"æ·˜baby"],
    "æ·˜èŒå® ": [r"æ·˜èŒå® ", r"IPTVæ·˜èŒå® ", r"èŒå® TV"],
    
    "é­…åŠ›è¶³çƒ": [r"é­…åŠ›è¶³çƒ", r"ä¸Šæµ·é­…åŠ›è¶³çƒ"],
    "ç›å½©é’å°‘": [r"ç›å½©é’å°‘", r"ç›å½©ç¾½æ¯›çƒ"],
    "æ±‚ç´¢çºªå½•": [r"æ±‚ç´¢çºªå½•", r"æ±‚ç´¢è®°å½•"],
    "é‡‘é¹°çºªå®": [r"é‡‘é¹°çºªå®", r"é‡‘é¹°è®°å®"],
    "çºªå®ç§‘æ•™": [r"çºªå®ç§‘æ•™", r"åŒ—äº¬çºªå®ç§‘æ•™"],
    "æ˜Ÿç©ºå«è§†": [r"æ˜Ÿç©ºå«è§†", r"æ˜Ÿç©ºè¡›è¦–", r"æ˜Ÿç©ºè¡›è§†", r"æ˜Ÿç©ºå«è¦–"],
    "CHANNEL[V]": [r"Channel\s*\[V\]", r"CHANNEL\s*\[V\]"],
    "å‡¤å‡°å«è§†ä¸­æ–‡å°": [r"å‡¤å‡°å«è§†ä¸­æ–‡å°", r"å‡¤å‡°ä¸­æ–‡", r"å‡¤å‡°å«è§†ä¸­æ–‡", r"å‡¤å‡°å«è§†"],
    "å‡¤å‡°å«è§†é¦™æ¸¯å°": [r"å‡¤å‡°å«è§†é¦™æ¸¯å°", r"å‡¤å‡°é¦™æ¸¯", r"å‡¤å‡°å«è§†é¦™æ¸¯"],
    "å‡¤å‡°å«è§†èµ„è®¯å°": [r"å‡¤å‡°å«è§†èµ„è®¯å°", r"å‡¤å‡°èµ„è®¯", r"å‡¤å‡°å’¨è¯¢", r"å‡¤å‡°å«è§†èµ„è®¯", r"å‡¤å‡°å«è§†å’¨è¯¢"],
    "å‡¤å‡°å«è§†ç”µå½±å°": [r"å‡¤å‡°å«è§†ç”µå½±å°", r"å‡¤å‡°ç”µå½±", r"é³³å‡°è¡›è¦–é›»å½±å°"],
    
    "èŒ¶é¢‘é“": [r"èŒ¶é¢‘é“", r"æ¹–å—èŒ¶é¢‘é“"],
    "å¿«ä¹å‚é’“": [r"å¿«ä¹å‚é’“"],
    "å…ˆé”‹ä¹’ç¾½": [r"å…ˆé”‹ä¹’ç¾½"],
    "å¤©å…ƒå›´æ£‹": [r"å¤©å…ƒå›´æ£‹"],
    "ä¹¦æ³•é¢‘é“": [r"ä¹¦æ³•é¢‘é“", r"ä¹¦æ³•ä¹¦ç”»"],
    "ç¯çƒå¥‡è§‚": [r"ç¯çƒå¥‡è§‚", r"ç¯çƒæ—…æ¸¸", r"å®‰å¹¿ç½‘ç»œ"],
    "ä¸­å­¦ç”Ÿ": [r"ä¸­å­¦ç”Ÿ", r"ä¸­å­¦ç”Ÿè¯¾å ‚"],
    "å®‰å¾½ç»¼è‰ºä½“è‚²": [r"å®‰å¾½ç»¼è‰ºä½“è‚²", r"å®‰å¾½ç»¼è‰º"],
    "å®‰å¾½å†œä¸šç§‘æ•™": [r"å®‰å¾½å†œä¸šç§‘æ•™", r"å®‰å¾½ç§‘æ•™"],
    "é©¬éå±±æ–°é—»ç»¼åˆ": [r"é©¬éå±±æ–°é—»ç»¼åˆ", r"é©¬éå±±æ–°é—»"],
    "æ¬¢ç¬‘å‰§åœº4K": [r"æ¬¢ç¬‘å‰§åœº4K", r"æ¬¢ç¬‘å‰§åœº"],
    "å¹¿ä¸œç æ±Ÿ": [r"å¹¿ä¸œç æ±Ÿ", r"ç æ±Ÿå°"],
    "å¹¿ä¸œç§‘æ•™": [r"å¹¿ä¸œç§‘æ•™", r"å¹¿ä¸œç§‘æ•™é«˜æ¸…ç”µä¿¡"],
    "å¹¿å·": [r"å¹¿å·", r"XFå¹¿å·å°"],
    "å˜‰ä½³å¡é€š": [r"å˜‰ä½³å¡é€š", r"å¹¿ä¸œå˜‰ä½³å¡é€š", r"ä½³ä½³å¡é€š"],
    "èŒ‚åç»¼åˆ": [r"èŒ‚åç»¼åˆ", r"èŒ‚åç»¼åˆé«˜æ¸…"],
    "å¹¿è¥¿å½±è§†": [r"å¹¿è¥¿å½±è§†"],
    "å¹¿è¥¿ç»¼è‰º": [r"å¹¿è¥¿ç»¼è‰º"],
    "å¹¿è¥¿æ–°é—»": [r"å¹¿è¥¿æ–°é—»"],
    "å¹¿è¥¿éƒ½å¸‚": [r"å¹¿è¥¿éƒ½å¸‚"],
    "ç‰æ—æ–°é—»ç»¼åˆ": [r"ç‰æ—æ–°é—»ç»¼åˆ", r"XFç‰æ—å°"],
    "é¾™ç¥¥æ—¶ä»£": [r"é¾™ç¥¥æ—¶ä»£", r"XFæœ‰çº¿ç”µå½±"],
    "æ±½æ‘©": [r"æ±½æ‘©", r"æ±½æ‘©é¢‘é“", r"é‡åº†æ±½æ‘©"],
    "æ¢¨å›­é¢‘é“": [r"æ¢¨å›­é¢‘é“", r"æ¢¨å›­", r"æ²³å—æ¢¨å›­"],
    "æ–‡ç‰©å®åº“": [r"æ–‡ç‰©å®åº“", r"æ²³å—æ–‡ç‰©å®åº“"],
    "æ­¦æœ¯ä¸–ç•Œ": [r"æ­¦æœ¯ä¸–ç•Œ", r"æ²³å—æ­¦æœ¯ä¸–ç•Œ"],
    "ä¹æ¸¸": [r"ä¹æ¸¸", r"ä¹æ¸¸é¢‘é“", r"ä¹æ¸¸çºªå®", r"å¤©å¤©ä¹æ¸¸"],
    "æ¬¢ç¬‘å‰§åœº": [r"æ¬¢ç¬‘å‰§åœº", r"ä¸Šæµ·æ¬¢ç¬‘å‰§åœº"],
    "ç”Ÿæ´»æ—¶å°š": [r"ç”Ÿæ´»æ—¶å°š", r"SiTVç”Ÿæ´»æ—¶å°š", r"ä¸Šæµ·ç”Ÿæ´»æ—¶å°š"],
    "éƒ½å¸‚å‰§åœº": [r"éƒ½å¸‚å‰§åœº", r"SiTVéƒ½å¸‚å‰§åœº", r"ä¸Šæµ·éƒ½å¸‚å‰§åœº"],
    "æ¸¸æˆé£äº‘": [r"æ¸¸æˆé£äº‘", r"SiTVæ¸¸æˆé£äº‘", r"ä¸Šæµ·æ¸¸æˆé£äº‘"],
    "é‡‘è‰²å­¦å ‚": [r"é‡‘è‰²å­¦å ‚", r"SiTVé‡‘è‰²å­¦å ‚", r"ä¸Šæµ·é‡‘è‰²å­¦å ‚"],
    "åŠ¨æ¼«ç§€åœº": [r"åŠ¨æ¼«ç§€åœº", r"SiTVåŠ¨æ¼«ç§€åœº", r"ä¸Šæµ·åŠ¨æ¼«ç§€åœº"],
    "å¡é…·å°‘å„¿": [r"å¡é…·å°‘å„¿", r"BRTVå¡é…·å°‘å„¿", r"å¡é…·åŠ¨ç”»", r"å¡é…·åŠ¨æ¼«", r"åŒ—äº¬å¡é…·"],
    "å“ˆå“ˆç‚«åŠ¨": [r"å“ˆå“ˆç‚«åŠ¨", r"ç‚«åŠ¨å¡é€š"],
    "ä¼˜æ¼«å¡é€š": [r"ä¼˜æ¼«å¡é€š", r"ä¼˜æ¼«æ¼«ç”»"],
    "é‡‘é¹°å¡é€š": [r"é‡‘é¹°å¡é€š", r"æ¹–å—é‡‘é¹°å¡é€š"],
    "ä¸­å›½äº¤é€š": [r"ä¸­å›½äº¤é€š", r"ä¸­å›½äº¤é€šé¢‘é“"],
    "ä¸­å›½å¤©æ°”": [r"ä¸­å›½å¤©æ°”", r"ä¸­å›½å¤©æ°”é¢‘é“"],
    "ç»å…¸ç”µå½±": [r"ç»å…¸ç”µå½±", r"IPTVç»å…¸ç”µå½±"],
    "ç²¾å½©å½±è§†": [r"ç²¾å½©å½±è§†", r"IPTVç²¾å½©å½±è§†"],
    "å–œå‰§å½±é™¢": [r"å–œå‰§å½±é™¢", r"IPTVå–œå‰§å½±é™¢"],
    "åŠ¨ä½œå½±é™¢": [r"åŠ¨ä½œå½±é™¢", r"IPTVåŠ¨ä½œå½±é™¢"],
    "ç²¾å“å‰§åœº": [r"ç²¾å“å‰§åœº", r"IPTVç²¾å“å‰§åœº"],
    "ç½‘ç»œæ£‹ç‰Œ": [r"ç½‘ç»œæ£‹ç‰Œ", r"IPTVç½‘ç»œæ£‹ç‰Œ"],
}

# æ·»åŠ æ•°å­—é¢‘é“çš„æ˜ å°„
for i in range(1, 100):
    CHANNEL_MAPPING[f"CHCåŠ¨ä½œç”µå½±{i}"] = [f"CHCåŠ¨ä½œç”µå½±{i}"]
    CHANNEL_MAPPING[f"CHCå®¶åº­å½±é™¢{i}"] = [f"CHCå®¶åº­å½±é™¢{i}"]
    CHANNEL_MAPPING[f"CHCå½±è¿·ç”µå½±{i}"] = [f"CHCå½±è¿·ç”µå½±{i}"]

RESULTS_PER_CHANNEL = 20

# è¯»å–å°æ ‡æ–‡ä»¶
def read_logo_file():
    logo_dict = {}
    logo_file = "Hotel/logo.txt"
    if os.path.exists(logo_file):
        try:
            with open(logo_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and ',' in line:
                        parts = line.split(',', 1)
                        channel_name = parts[0].strip()
                        logo_url = parts[1].strip()
                        logo_dict[channel_name] = logo_url
        except Exception as e:
            print(f"è¯»å–å°æ ‡æ–‡ä»¶é”™è¯¯: {e}")
    return logo_dict

# æ£€æµ‹IP:ç«¯å£å¯ç”¨æ€§
def check_ip_availability(ip_port, timeout=2):
    """æ£€æµ‹IP:ç«¯å£æ˜¯å¦å¯ç”¨"""
    try:
        # å°è¯•è¿æ¥HTTPæœåŠ¡
        test_urls = [
            f"http://{ip_port}/",
            f"http://{ip_port}/iptv/live/1000.json?key=txiptv",
            f"http://{ip_port}/ZHGXTV/Public/json/live_interface.txt"
        ]
        
        for url in test_urls:
            try:
                response = requests.get(url, timeout=timeout, headers=HEADERS)
                if response.status_code == 200:
                    return True
            except:
                continue
                
        return False
    except Exception as e:
        return False

# æ‰¹é‡æ£€æµ‹IPå¯ç”¨æ€§å¹¶æ›´æ–°æ–‡ä»¶
def check_and_update_ip_file(province_file):
    """æ£€æµ‹IPå¯ç”¨æ€§å¹¶æ›´æ–°æ–‡ä»¶"""
    print(f"\nå¼€å§‹æ£€æµ‹ {province_file} ä¸­çš„IPå¯ç”¨æ€§...")
    
    available_ips = []
    all_ips = []
    
    # è¯»å–IPæ–‡ä»¶
    try:
        with open(province_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    all_ips.append(line)
    except Exception as e:
        print(f"è¯»å–IPæ–‡ä»¶é”™è¯¯: {e}")
        return
    
    total_ips = len(all_ips)
    print(f"éœ€è¦æ£€æµ‹ {total_ips} ä¸ªIP")
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ£€æµ‹
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = {}
        for ip_port in all_ips:
            future = executor.submit(check_ip_availability, ip_port)
            futures[future] = ip_port
        
        completed = 0
        for future in as_completed(futures):
            ip_port = futures[future]
            try:
                is_available = future.result()
                completed += 1
                
                if is_available:
                    available_ips.append(ip_port)
                    print(f"âœ“ {ip_port} å¯ç”¨ ({completed}/{total_ips})")
                else:
                    print(f"âœ— {ip_port} ä¸å¯ç”¨ ({completed}/{total_ips})")
                    
                # æ¯æ£€æµ‹10ä¸ªIPæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if completed % 10 == 0 or completed == total_ips:
                    print(f"è¿›åº¦: {completed}/{total_ips} ({completed/total_ips*100:.1f}%) - å¯ç”¨: {len(available_ips)} ä¸ª")
                    
            except Exception as e:
                completed += 1
                print(f"âœ— {ip_port} æ£€æµ‹å¤±è´¥ ({completed}/{total_ips})")
    
    # æ›´æ–°IPæ–‡ä»¶ï¼Œåªä¿ç•™å¯ç”¨çš„IP
    if available_ips:
        with open(province_file, 'w', encoding='utf-8') as f:
            for ip_port in available_ips:
                f.write(f"{ip_port}\n")
        
        print(f"\nâœ“ å·²æ›´æ–° {province_file}")
        print(f"  åŸå§‹IPæ•°é‡: {total_ips}")
        print(f"  å¯ç”¨IPæ•°é‡: {len(available_ips)}")
        print(f"  ä¸å¯ç”¨IPå·²åˆ é™¤: {total_ips - len(available_ips)}")
    else:
        print(f"\nâœ— æ²¡æœ‰å¯ç”¨çš„IPï¼Œæ–‡ä»¶ {province_file} å°†ä¿æŒä¸å˜")
    
    return available_ips

# è¯»å–æ–‡ä»¶å¹¶è®¾ç½®å‚æ•°
def read_config(config_file):
    ip_configs = []
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    if ':' in line:
                        ip_part, port = line.split(':', 1)
                        a, b, c, d = ip_part.split('.')
                        ip = f"{a}.{b}.{c}.1"
                        ip_configs.append((ip, port))
        return ip_configs
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
        return []

# å‘é€getè¯·æ±‚æ£€æµ‹urlæ˜¯å¦å¯è®¿é—®
def check_ip_port(ip_port, url_end):
    try:
        url = f"http://{ip_port}{url_end}"
        resp = requests.get(url, timeout=2)
        resp.raise_for_status()
        if "tsfile" in resp.text or "hls" in resp.text:
            print(f"{url} è®¿é—®æˆåŠŸ")
            return url
    except:
        return None

# å¤šçº¿ç¨‹æ£€æµ‹urlï¼Œè·å–æœ‰æ•ˆip_port
def scan_ip_port(ip, port, url_end):
    valid_urls = []
    a, b, c, d = map(int, ip.split('.'))
    ip_ports = [f"{a}.{b}.{c}.{x}:{port}" for x in range(1, 256)]
    with ThreadPoolExecutor(max_workers=100) as executor:
        futures = {executor.submit(check_ip_port, ip_port, url_end): ip_port for ip_port in ip_ports}
        for future in as_completed(futures):
            result = future.result()
            if result:
                valid_urls.append(result)
    return valid_urls    

# å‘é€GETè¯·æ±‚è·å–JSONæ–‡ä»¶, è§£æJSONæ–‡ä»¶, è·å–é¢‘é“ä¿¡æ¯
def extract_channels(url):
    hotel_channels = []
    try:
        json_url = f"{url}"
        urls = url.split('/', 3)
        url_x = f"{urls[0]}//{urls[2]}"
        if "iptv" in json_url:
            response = requests.get(json_url, timeout=2)
            json_data = response.json()
            for item in json_data['data']:
                if isinstance(item, dict):
                    name = item.get('name')
                    urlx = item.get('url')
                    if "tsfile" in urlx:
                        urld = f"{url_x}{urlx}"
                        hotel_channels.append((name, urld))
        elif "ZHGXTV" in json_url:
            response = requests.get(json_url, timeout=2)
            json_data = response.content.decode('utf-8')
            data_lines = json_data.split('\n')
            for line in data_lines:
                if "," in line and "hls" in line:
                    name, channel_url = line.strip().split(',')
                    parts = channel_url.split('/', 3)
                    if len(parts) >= 4:
                        urld = f"{url_x}/{parts[3]}"
                        hotel_channels.append((name, urld))
        return hotel_channels
    except Exception:
        return []

# æµ‹é€Ÿ
def speed_test(channels):
    def show_progress():
        while checked[0] < len(channels):
            numberx = checked[0] / len(channels) * 100
            print(f"å·²æµ‹è¯•{checked[0]}/{len(channels)}ï¼Œå¯ç”¨é¢‘é“:{len(results)}ä¸ªï¼Œè¿›åº¦:{numberx:.2f}%")
            time.sleep(5)
    
    def worker():
        while True:
            try:
                channel_name, channel_url = task_queue.get()
                try:
                    channel_url_t = channel_url.rstrip(channel_url.split('/')[-1])
                    lines = requests.get(channel_url, timeout=2).text.strip().split('\n')
                    ts_lists = [line.split('/')[-1] for line in lines if line.startswith('#') == False]
                    if ts_lists:
                        ts_url = channel_url_t + ts_lists[0]
                        ts_lists_0 = ts_lists[0].rstrip(ts_lists[0].split('.ts')[-1])
                        with eventlet.Timeout(5, False):
                            start_time = time.time()
                            cont = requests.get(ts_url, timeout=2).content
                            resp_time = (time.time() - start_time) * 1                    
                        if cont and resp_time > 0:
                            checked[0] += 1
                            temp_filename = f"temp_{hash(channel_url)}.ts"
                            with open(temp_filename, 'wb') as f:
                                f.write(cont)
                            normalized_speed = len(cont) / resp_time / 1024 / 1024
                            os.remove(temp_filename)
                            # è¿‡æ»¤æ‰é€Ÿåº¦è¿‡æ…¢çš„é¢‘é“ï¼ˆâ‰¤0.001 MB/sï¼‰
                            if normalized_speed > 0.001:
                                result = channel_name, channel_url, f"{normalized_speed:.3f}"
                                print(f"âœ“ {channel_name}, {channel_url}: {normalized_speed:.3f} MB/s")
                                results.append(result)
                            else:
                                print(f"Ã— {channel_name}, {channel_url}: é€Ÿåº¦è¿‡æ…¢ ({normalized_speed:.3f} MB/s)ï¼Œå·²è¿‡æ»¤")
                        else:
                            checked[0] += 1
                except Exception as e:
                    checked[0] += 1
            except:
                checked[0] += 1
            finally:
                task_queue.task_done()
    
    task_queue = Queue()
    results = []
    checked = [0]
    
    Thread(target=show_progress, daemon=True).start()
    
    for _ in range(min(10, len(channels))):
        Thread(target=worker, daemon=True).start()
    
    for channel in channels:
        task_queue.put(channel)
    
    task_queue.join()
    return results

# ç»Ÿä¸€é¢‘é“åç§° - æ”¹è¿›ç‰ˆæœ¬
def unify_channel_name(channels_list):
    new_channels_list = []
    
    for name, channel_url, speed in channels_list:
        original_name = name
        unified_name = None
        
        # æ¸…ç†åç§°
        clean_name = name.strip()
        
        # é¦–å…ˆå°è¯•å®Œå…¨åŒ¹é…
        for standard_name, patterns in CHANNEL_MAPPING.items():
            for pattern in patterns:
                # å¦‚æœæ¨¡å¼æ˜¯æ­£åˆ™è¡¨è¾¾å¼
                if pattern.startswith('r"') or pattern.startswith("r'"):
                    # å»é™¤æ­£åˆ™è¡¨è¾¾å¼çš„å‰ç¼€
                    pattern = pattern[2:-1] if pattern.endswith('"') or pattern.endswith("'") else pattern[2:]
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡ŒåŒ¹é…
                try:
                    if re.search(pattern, clean_name, re.IGNORECASE):
                        unified_name = standard_name
                        break
                except re.error:
                    # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼é”™è¯¯ï¼Œå°è¯•ç›´æ¥å­—ç¬¦ä¸²åŒ¹é…
                    if pattern.lower() in clean_name.lower():
                        unified_name = standard_name
                        break
            if unified_name:
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œåˆ™ä¿ç•™åŸåç§°
        if not unified_name:
            unified_name = clean_name
        
        new_channels_list.append(f"{unified_name},{channel_url},{speed}\n")
        if original_name != unified_name:
            print(f"é¢‘é“åç§°ç»Ÿä¸€: '{original_name}' -> '{unified_name}'")
    
    return new_channels_list

# å®šä¹‰æ’åºå‡½æ•°
def channel_key(channel_name):
    match = re.search(r'\d+', channel_name)
    return int(match.group()) if match else float('inf')

# åˆ†ç±»é¢‘é“
def classify_channels_by_category(channels_data):
    categorized_channels = {}
    
    # åˆå§‹åŒ–åˆ†ç±»å­—å…¸
    for category in CHANNEL_CATEGORIES.keys():
        categorized_channels[category] = []
    
    # æ·»åŠ "å…¶ä»–"åˆ†ç±»
    categorized_channels["å…¶ä»–é¢‘é“"] = []
    
    for line in channels_data:
        try:
            parts = line.strip().split(',')
            if len(parts) < 2:
                continue
            name = parts[0]
            url = parts[1]
            speed = parts[2] if len(parts) > 2 else "0.000"
            assigned = False
            
            # æŸ¥æ‰¾æ‰€å±åˆ†ç±»
            for category, channel_list in CHANNEL_CATEGORIES.items():
                if name in channel_list:
                    categorized_channels[category].append((name, url, speed))
                    assigned = True
                    break
            
            # å¦‚æœæœªåˆ†é…åˆ°ä»»ä½•åˆ†ç±»ï¼Œåˆ™æ”¾å…¥"å…¶ä»–"
            if not assigned:
                categorized_channels["å…¶ä»–é¢‘é“"].append((name, url, speed))
        except Exception as e:
            print(f"åˆ†ç±»é¢‘é“æ—¶å‡ºé”™: {e}, è¡Œ: {line}")
            continue
    
    return categorized_channels

# ç”ŸæˆM3Uæ–‡ä»¶
def generate_m3u_file(txt_file_path, m3u_file_path):
    """ä»txtæ–‡ä»¶ç”Ÿæˆm3uæ–‡ä»¶"""
    print(f"å¼€å§‹ç”ŸæˆM3Uæ–‡ä»¶: {m3u_file_path}")
    
    # è¯»å–å°æ ‡æ–‡ä»¶
    logo_dict = read_logo_file()
    
    # EPGé“¾æ¥
    epg_url = "https://gh.catmak.name/https://raw.githubusercontent.com/Guovin/iptv-api/refs/heads/master/output/epg/epg.gz"
    
    with open(m3u_file_path, 'w', encoding='utf-8') as m3u_file:
        # å†™å…¥M3Uå¤´éƒ¨
        m3u_file.write(f'#EXTM3U x-tvg-url="{epg_url}"\n')
        
        # è¯»å–txtæ–‡ä»¶
        with open(txt_file_path, 'r', encoding='utf-8') as txt_file:
            current_group = ""
            
            for line in txt_file:
                line = line.strip()
                if not line:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†ç»„è¡Œ
                if line.endswith(',#genre#'):
                    current_group = line.replace(',#genre#', '')
                    continue
                
                # å¤„ç†é¢‘é“è¡Œ
                if ',' in line and not line.startswith('#'):
                    try:
                        parts = line.split(',')
                        if len(parts) >= 2:
                            channel_name = parts[0]
                            channel_url = parts[1]
                            
                            # è·å–å°æ ‡
                            logo_url = logo_dict.get(channel_name, "")
                            
                            # å†™å…¥M3Uæ¡ç›®
                            m3u_file.write(f'#EXTINF:-1 tvg-name="{channel_name}" tvg-logo="{logo_url}" group-title="{current_group}",{channel_name}\n')
                            m3u_file.write(f'{channel_url}\n')
                    except Exception as e:
                        print(f"å¤„ç†é¢‘é“è¡Œé”™è¯¯: {line}, é”™è¯¯: {e}")
    
    print(f"M3Uæ–‡ä»¶å·²ç”Ÿæˆ: {m3u_file_path}")

# è·å–é…’åº—æºæµç¨‹        
def hotel_iptv(config_file):
    # å…ˆæ£€æµ‹å¹¶æ›´æ–°IPæ–‡ä»¶
    available_ips = check_and_update_ip_file(config_file)
    
    if not available_ips:
        print(f"æ²¡æœ‰å¯ç”¨çš„IPï¼Œè·³è¿‡ {config_file}")
        return
    
    ip_configs = set(read_config(config_file))
    valid_urls = []
    channels = []
    configs = []
    url_ends = ["/iptv/live/1000.json?key=txiptv", "/ZHGXTV/Public/json/live_interface.txt"]
    
    for url_end in url_ends:
        for ip, port in ip_configs:
            configs.append((ip, port, url_end))
    
    for ip, port, url_end in configs:
        valid_urls.extend(scan_ip_port(ip, port, url_end))
    
    print(f"æ‰«æå®Œæˆï¼Œè·å–æœ‰æ•ˆurlå…±ï¼š{len(valid_urls)}ä¸ª")
    
    for valid_url in valid_urls:
        channels.extend(extract_channels(valid_url))
    
    print(f"å…±è·å–é¢‘é“ï¼š{len(channels)}ä¸ª\nå¼€å§‹æµ‹é€Ÿ")
    results = speed_test(channels)
    
    # å¯¹é¢‘é“è¿›è¡Œæ’åº
    results.sort(key=lambda x: -float(x[2]))
    results.sort(key=lambda x: channel_key(x[0]))
    
    # ç»Ÿä¸€é¢‘é“åç§°
    unified_channels = unify_channel_name(results)
    
    # å†™å…¥åŸå§‹æ•°æ®æ–‡ä»¶
    with open('1.txt', 'a', encoding='utf-8') as f:
        for line in unified_channels:
            f.write(line.split(',')[0] + ',' + line.split(',')[1] + '\n')
    print("æµ‹é€Ÿå®Œæˆ")

# ä¸»å‡½æ•°
def main():
    # æ˜¾ç¤ºè„šæœ¬å¼€å§‹æ—¶é—´
    start_time = datetime.datetime.now()
    print(f"è„šæœ¬å¼€å§‹è¿è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    
    # ç¬¬ä¸€æ­¥ï¼šè·å–IPå¹¶æŒ‰ç…§çœä»½åˆ†ç±»
    print("\nå¼€å§‹è·å–IPåˆ—è¡¨...")
    ips = fetch_ips_from_urls()
    print(f"è·å–åˆ° {len(ips)} ä¸ªIP")
    
    # ä¿å­˜IPåˆ°çœä»½æ–‡ä»¶
    save_ips_by_province(ips)
    
    # ç¬¬äºŒæ­¥ï¼šå¤„ç†æ¯ä¸ªçœä»½çš„IP
    province_files = [f for f in os.listdir(IP_DIR) if f.endswith('.txt')]
    
    for province_file in province_files:
        province_name = province_file.replace('.txt', '')
        print(f"\nå¤„ç† {province_name} çš„IP...")
        
        config_file = os.path.join(IP_DIR, province_file)
        hotel_iptv(config_file)
    
    # ç¬¬ä¸‰æ­¥ï¼šè¯»å–ç»Ÿä¸€åçš„é¢‘é“æ•°æ®å¹¶è¿›è¡Œåˆ†ç±»
    if not os.path.exists('1.txt'):
        print("æ²¡æœ‰æ‰¾åˆ°é¢‘é“æ•°æ®æ–‡ä»¶")
        return
    
    with open('1.txt', 'r', encoding='utf-8') as f:
        raw_lines = f.readlines()
    
    # è½¬æ¢ä¸º(channel, url, speed)æ ¼å¼
    channels_data = []
    for line in raw_lines:
        if ',' in line and line.strip():
            parts = line.strip().split(',')
            if len(parts) >= 2:
                name = parts[0]
                url = parts[1]
                speed = parts[2] if len(parts) > 2 else "0.000"
                channels_data.append(f"{name},{url},{speed}")
    
    # å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»
    categorized = classify_channels_by_category(channels_data)
    
    # å†™å…¥åˆ†ç±»æ–‡ä»¶
    file_paths = []
    for category, channels in categorized.items():
        if channels:
            # å¯¹æ¯ä¸ªåˆ†ç±»å†…çš„é¢‘é“è¿›è¡Œæ’åº
            channels.sort(key=lambda x: channel_key(x[0]))
            
            # é™åˆ¶æ¯ä¸ªé¢‘é“çš„ç»“æœæ•°é‡
            channel_count = {}
            filtered_channels = []
            
            for name, url, speed in channels:
                if name not in channel_count:
                    channel_count[name] = 0
                
                if channel_count[name] < RESULTS_PER_CHANNEL:
                    filtered_channels.append((name, url, speed))
                    channel_count[name] += 1
            
            # æŒ‰ç…§é€Ÿåº¦æ’åº
            filtered_channels.sort(key=lambda x: -float(x[2]))
            
            # å†™å…¥æ–‡ä»¶
            filename = f"{category.replace('é¢‘é“', '')}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"{category},#genre#\n")
                for name, url, speed in filtered_channels:
                    f.write(f"{name},{url}\n")
            
            file_paths.append(filename)
            print(f"å·²ä¿å­˜ {len(filtered_channels)} ä¸ªé¢‘é“åˆ° {filename}")
    
    # åˆå¹¶å†™å…¥æ–‡ä»¶
    file_contents = []
    
    for file_path in file_paths:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding="utf-8") as f:
                content = f.read()
                file_contents.append(content)
    
    # è·å–åŒ—äº¬æ—¶é—´
    beijing_time = datetime.datetime.now()
    current_time = beijing_time.strftime("%Y/%m/%d %H:%M")
    
    with open("1.txt", "w", encoding="utf-8") as f:
        f.write(f"{current_time}æ›´æ–°,#genre#\n")
        f.write(f"æµ™æ±Ÿå«è§†,http://ali-m-l.cztv.com/channels/lantian/channel001/1080p.m3u8\n")
        for content in file_contents:
            f.write(f"\n{content}")
    
    # åŸå§‹é¡ºåºå»é‡
    with open('1.txt', 'r', encoding="utf-8") as f:
        lines = f.readlines()
    
    unique_lines = [] 
    seen_lines = set() 
    for line in lines:
        if line not in seen_lines:
            unique_lines.append(line)
            seen_lines.add(line)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = "Hotel"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # å†™å…¥txtæ–‡ä»¶
    txt_output_path = 'Hotel/iptv.txt'
    with open(txt_output_path, 'w', encoding="utf-8") as f:
        f.writelines(unique_lines)
    
    # ç”ŸæˆM3Uæ–‡ä»¶
    m3u_output_path = 'Hotel/iptv.m3u'
    generate_m3u_file(txt_output_path, m3u_output_path)
    
    # ç§»é™¤è¿‡ç¨‹æ–‡ä»¶
    files_to_remove = ["1.txt"] + file_paths
    for file in files_to_remove:
        if os.path.exists(file):
            os.remove(file)
    
    # æ˜¾ç¤ºè„šæœ¬ç»“æŸæ—¶é—´
    end_time = datetime.datetime.now()
    print(f"\nè„šæœ¬ç»“æŸè¿è¡Œæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    
    # è®¡ç®—è¿è¡Œæ—¶é—´
    run_time = end_time - start_time
    hours, remainder = divmod(run_time.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    print(f"æ€»è¿è¡Œæ—¶é—´: {hours}å°æ—¶{minutes}åˆ†{seconds}ç§’")
    print("ä»»åŠ¡è¿è¡Œå®Œæ¯•ï¼Œæ‰€æœ‰é¢‘é“åˆå¹¶åˆ°iptv.txtå’Œiptv.m3u")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹IPçˆ¬å–å’Œåˆ†ç±»...")
    print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ° {IP_DIR} ç›®å½•")
    first_stage()
    main()
